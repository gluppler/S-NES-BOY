# 2.6 Advanced Optimization Techniques

## System Applicability

**This document applies to:**
- ✅ **: Fully compatible (same hardware constraints)


## Concept Definition


## Subsystems Involved

* **CPU: Instruction selection, addressing modes, branch optimization
* **Memory: Zero page usage, memory layout, cache-like access patterns
* **PPU: VRAM update efficiency, OAM management, rendering pipeline
* **ROM: Lookup tables, data compression, code organization

## Core Optimization Principles

### 1. Zero Page Priority

**Rule: Variables accessed >10 times per frame should be in zero page.

**Why: Zero page access saves 1 cycle per access (3 cycles vs 4 cycles for absolute).

**Example:
```asm
; ❌ BAD: Absolute addressing for hot variable
player_x = $0300
update_player:
    LDA player_x      ; 4 cycles
    CLC
    ADC #1
    STA player_x      ; 4 cycles
    ; Total: 8 cycles

; ✅ GOOD: Zero page addressing
zp_player_x = $09
update_player:
    LDA zp_player_x   ; 3 cycles
    CLC
    ADC #1
    STA zp_player_x   ; 3 cycles
    ; Total: 6 cycles (25% faster)
```

**Impact: In a tight loop updating 10 entities, zero page saves 20 cycles per frame.

### 2. Addressing Mode Selection

**Rule: Use the fastest addressing mode that fits your data layout.

**Cycle Costs:
- Immediate (`LDA #value`): 2 cycles
- Zero Page (`LDA $00`): 3 cycles
- Zero Page,X (`LDA $00,X`): 4 cycles
- Absolute (`LDA $0300`): 4 cycles
- Absolute,X (`LDA $0300,X`): 4-5 cycles (+1 if page crossed)
- (Indirect,X): 6 cycles
- (Indirect),Y: 5-6 cycles (+1 if page crossed)

**Optimization Strategy:
```asm
; ❌ BAD: Absolute indexed when zero page would work
entity_data = $0300
    LDX #0
    LDA entity_data,X  ; 4 cycles

; ✅ GOOD: Zero page indexed
zp_entity_base = $10
    LDX #0
    LDA zp_entity_base,X  ; 4 cycles (same, but allows better layout)

; ✅ BETTER: Restructure to use zero page base
zp_entity_ptr = $10  ; 16-bit pointer
    LDY #0
    LDA (zp_entity_ptr),Y  ; 5 cycles, but more flexible
```

### 3. Branch Optimization

**Rule: Structure code to minimize taken branches and page boundary crossings.

**Branch Penalties:
- Not taken: 2 cycles
- Taken: 3 cycles
- Taken + page cross: 4 cycles

**Optimization Techniques:

```asm
; ❌ BAD: Multiple branches in hot path
check_collision:
    LDA player_x
    CMP enemy_x
    BNE no_collision    ; 3 cycles if taken
    LDA player_y
    CMP enemy_y
    BNE no_collision    ; 3 cycles if taken
    ; Collision detected
no_collision:
    RTS

; ✅ GOOD: Early exit, minimize branches
check_collision:
    LDA player_x
    CMP enemy_x
    BNE no_collision    ; 3 cycles
    LDA player_y
    CMP enemy_y
    BEQ collision       ; 3 cycles (only one taken branch)
no_collision:
    RTS
collision:
    ; Handle collision
    RTS

; ✅ BETTER: Use bitwise operations when possible
check_collision:
    LDA player_x
    EOR enemy_x         ; XOR: 0 if equal
    BNE no_collision
    LDA player_y
    EOR enemy_y
    BNE no_collision
    ; Collision (both XORs = 0)
```

### 4. Loop Unrolling

**Rule: Unroll small, hot loops to eliminate branch overhead.

**When to Use: Loops with <8 iterations that run every frame.

**Example:
```asm
; ❌ BAD: Small loop with branch overhead
clear_buffer:
    LDX #0
clear_loop:
    LDA #0
    STA buffer,X
    INX
    CPX #4              ; 2 cycles
    BNE clear_loop       ; 3 cycles (taken 3 times)
    ; Total: ~20 cycles

; ✅ GOOD: Unrolled loop
clear_buffer:
    LDA #0
    STA buffer+0        ; 4 cycles
    STA buffer+1        ; 4 cycles
    STA buffer+2        ; 4 cycles
    STA buffer+3        ; 4 cycles
    ; Total: 16 cycles (20% faster)
```

**Trade-off: Code size increases, but speed improves. Use for hot paths only.

### 5. Lookup Tables vs Computation

**Rule: Pre-compute values in ROM lookup tables when computation >4 cycles.

**When to Use: Mathematical operations, coordinate conversions, tile lookups.

**Example:
```asm
; ❌ BAD: Compute division at runtime
divide_by_8:
    LSR A               ; /2
    LSR A               ; /4
    LSR A               ; /4
    ; Total: 6 cycles

; ✅ GOOD: Lookup table (if used frequently)
divide_by_8_table:
    .byte 0, 0, 0, 0, 0, 0, 0, 0    ; 0-7 → 0
    .byte 1, 1, 1, 1, 1, 1, 1, 1    ; 8-15 → 1
    .byte 2, 2, 2, 2, 2, 2, 2, 2    ; 16-23 → 2
    ; ... etc

divide_by_8:
    TAX
    LDA divide_by_8_table,X  ; 4 cycles (faster for complex operations)
```

**Memory Trade-off: Lookup tables use ROM (plentiful) vs computation uses CPU cycles (limited).

### 6. Struct-of-Arrays Pattern

**Rule: Organize entity data as separate arrays (all X positions, then all Y positions).

**Why: Enables batch processing and better cache-like behavior.

**Example:
```asm
; ❌ BAD: Array-of-structs (random access)
entity_struct_size = 8
entity_data = $0300
    ; Each entity: X(1), Y(1), VX(1), VY(1), Type(1), State(1), Timer(1), Flags(1)
    ; To update all X positions: random access every 8 bytes

; ✅ GOOD: Struct-of-arrays (sequential access)
entity_x = $0300      ; 10 bytes: all X positions
entity_y = $030A      ; 10 bytes: all Y positions
entity_vx = $0314     ; 10 bytes: all X velocities
entity_vy = $031E     ; 10 bytes: all Y velocities

; Update all positions efficiently
update_entities:
    LDY #0
update_loop:
    ; Update X (sequential access)
    LDA entity_x,Y
    CLC
    ADC entity_vx,Y
    STA entity_x,Y
    
    ; Update Y (sequential access)
    LDA entity_y,Y
    CLC
    ADC entity_vy,Y
    STA entity_y,Y
    
    INY
    CPY #10
    BNE update_loop
```

**Benefits: 
- Sequential memory access (faster)
- Easier to batch process
- Better for SIMD-like operations

### 7. Register Reuse

**Rule: Keep frequently used values in CPU registers (A, X, Y) to avoid memory access.

**Example:
```asm
; ❌ BAD: Repeated memory access
process_data:
    LDA data_ptr       ; 3 cycles
    STA temp
    LDA data_ptr+1
    STA temp+1
    ; ... later ...
    LDA temp           ; 3 cycles
    STA data_ptr       ; 3 cycles
    LDA temp+1
    STA data_ptr+1

; ✅ GOOD: Keep in registers
process_data:
    LDA data_ptr       ; 3 cycles
    TAX                ; 2 cycles (keep low byte in X)
    LDA data_ptr+1
    TAY                ; 2 cycles (keep high byte in Y)
    ; ... process ...
    TXA                ; 2 cycles
    STA data_ptr       ; 3 cycles
    TYA
    STA data_ptr+1
    ; Saves 6 cycles by avoiding temp variable
```

### 8. Inline vs Subroutine

**Rule: Inline code <10 cycles that's called >5 times per frame.

**Trade-off: Code size vs execution speed.

**Example:
```asm
; ❌ BAD: Small function called frequently
increment_counter:
    INC counter
    RTS                 ; 6 cycles (RTS overhead)

; Called 10 times per frame = 60 cycles overhead

; ✅ GOOD: Inline for hot paths
    ; Inline increment (2 cycles)
    INC counter
    ; No RTS overhead
    ; 10 calls = 20 cycles (67% faster)
```

**When to Use Subroutines: Code >20 cycles, called <3 times per frame, or code reuse is important.

### 9. NMI Handler Optimization

**Rule: Minimize NMI handler time (<2000 cycles) to prevent frame drops.

**Critical Optimizations:

```asm
; ❌ BAD: Slow operations in NMI
nmi:
    PHA
    TXA
    PHA
    TYA
    PHA
    
    LDA $2002
    
    ; Slow: Update OAM byte-by-byte
    LDX #0
    LDY #0
copy_oam:
    LDA oam_buffer,X
    STA $2003           ; Wrong! Should use DMA
    INX
    INY
    CPY #256
    BNE copy_oam       ; ~1000+ cycles (too slow)
    
    PLA
    TAY
    PLA
    TAX
    PLA
    RTI

; ✅ GOOD: Use OAM DMA
nmi:
    PHA
    TXA
    PHA
    TYA
    PHA
    
    LDA $2002
    
    ; Fast: OAM DMA (513 cycles, hardware-accelerated)
    LDA #0
    STA $2003
    LDA #>oam_buffer
    STA $4014           ; DMA transfer
    
    ; Update scroll (must be done every frame)
    LDA scroll_x
    STA $2005
    LDA scroll_y
    STA $2005
    
    ; Update PPU control
    LDA ppu_ctrl
    STA $2000
    
    INC frame_counter
    LDA #1
    STA frame_ready
    
    PLA
    TAY
    PLA
    TAX
    PLA
    RTI
    ; Total: ~600 cycles (well under 2000 cycle budget)
```

### 10. VRAM Update Optimization

**Rule: Minimize VRAM writes during VBlank. Batch updates, use dirty flags.

**VBlank Budget: ~2,270 cycles (NTSC), ~1,135 bytes theoretical maximum.

**Optimization Techniques:

```asm
; ❌ BAD: Writing individual tiles
update_background:
    LDA $2002
    LDA #$20
    STA $2006
    LDA #$00
    STA $2006
    LDA tile_to_update
    STA $2007           ; Each write: ~6 cycles (address setup + write)
    ; 100 tiles = 600 cycles

; ✅ GOOD: Batch updates, minimize address changes
update_background:
    LDA $2002
    LDA #$20
    STA $2006
    LDA #$00
    STA $2006
    ; Write all tiles sequentially (auto-increment)
    LDX #0
update_loop:
    LDA bg_update_buffer,X
    STA $2007           ; 2 cycles per tile (address already set)
    INX
    CPX bg_update_count
    BNE update_loop
    ; 100 tiles = ~250 cycles (60% faster)
```

### 11. Conditional Elimination

**Rule: Eliminate unnecessary conditionals in hot paths.

**Example:
```asm
; ❌ BAD: Redundant check
update_entity:
    LDA entity_active,Y
    BEQ skip            ; Check if active
    LDA entity_type,Y
    CMP #TYPE_ENEMY
    BNE skip            ; Check type
    ; Update enemy
skip:
    RTS

; ✅ GOOD: Pre-filter inactive entities
update_entities:
    ; Only process active enemies (pre-filtered list)
    LDY #0
update_loop:
    ; No active check needed (already filtered)
    LDA enemy_x,Y
    ; ... update ...
    INY
    CPY active_enemy_count
    BNE update_loop
```

### 12. Bit Manipulation

**Rule: Use bit operations for flags and state machines.

**Example:
```asm
; ❌ BAD: Separate boolean variables
entity_visible = $0300
entity_moving = $0301
entity_attacking = $0302

check_entity:
    LDA entity_visible  ; 3 cycles
    BEQ skip
    LDA entity_moving   ; 3 cycles
    BEQ skip
    ; ...

; ✅ GOOD: Bit flags in single byte
entity_flags = $0300
    ; Bit 0: visible
    ; Bit 1: moving
    ; Bit 2: attacking

check_entity:
    LDA entity_flags    ; 3 cycles
    AND #%00000111       ; 2 cycles (check all flags at once)
    BEQ skip
    ; All flags checked in 5 cycles vs 9 cycles
```

### 13. Multiplication/Division Optimization

**Rule: Use bit shifts for powers of 2, lookup tables for other values.

**Powers of 2:
```asm
; Multiply by 2: ASL A (2 cycles)
; Multiply by 4: ASL A, ASL A (4 cycles)
; Multiply by 8: ASL A, ASL A, ASL A (6 cycles)
; Divide by 2: LSR A (2 cycles)
; Divide by 4: LSR A, LSR A (4 cycles)
```

**Non-powers of 2:
```asm
; Multiply by 3: A + (A * 2)
    ASL A           ; A * 2
    CLC
    ADC original_A  ; A * 2 + A = A * 3

; Multiply by 5: A + (A * 4)
    ASL A
    ASL A           ; A * 4
    CLC
    ADC original_A  ; A * 4 + A = A * 5

; For complex multiplications: Use lookup table
multiply_by_7_table:
    .byte 0, 7, 14, 21, 28, 35, 42, 49, ...
```

### 14. Sprite Optimization

**Rule: Minimize sprite count, use dirty flags, batch OAM updates.

**Techniques:

```asm
; ✅ GOOD: Sprite dirty flag system
sprite_dirty = $00      ; Zero page: dirty flag
oam_buffer = $0200

update_sprite:
    ; Only update if sprite changed
    LDA sprite_dirty
    BEQ skip_update
    
    ; Update OAM buffer
    LDX sprite_index
    LDA sprite_y
    STA oam_buffer,X
    INX
    LDA sprite_tile
    STA oam_buffer,X
    INX
    LDA sprite_attr
    STA oam_buffer,X
    INX
    LDA sprite_x
    STA oam_buffer,X
    
    LDA #0
    STA sprite_dirty    ; Clear dirty flag
skip_update:
    RTS

; ✅ GOOD: Sprite culling (don't update off-screen sprites)
update_sprites:
    LDY #0
update_loop:
    LDA sprite_y,Y
    CMP #240            ; Off-screen threshold
    BCS skip_sprite     ; Skip if Y >= 240
    ; Update sprite
skip_sprite:
    INY
    CPY sprite_count
    BNE update_loop
```

### 15. Memory Access Patterns

**Rule: Access memory sequentially when possible. Avoid random access in hot loops.

**Example:
```asm
; ❌ BAD: Random access pattern
lookup_table = $0400
    LDX index1
    LDA lookup_table,X  ; Random access
    LDX index2
    LDA lookup_table,X  ; Random access (cache miss)

; ✅ GOOD: Sequential access
    LDY #0
process_loop:
    LDA lookup_table,Y  ; Sequential access
    ; Process
    INY
    CPY count
    BNE process_loop
```

### 16. Code Organization for Speed

**Rule: Place hot code in fast memory (ROM), organize for sequential execution.

**Techniques:
- Place frequently called functions early in ROM
- Group related functions together (reduces page crossings)
- Use local labels for short jumps (`.label:` instead of `label:`)

**Example:
```asm
; ✅ GOOD: Local labels for short jumps
update_entity:
    LDA entity_type,Y
    BEQ .skip_enemy
    ; Enemy update code
.skip_enemy:
    INY
    CPY entity_count
    BNE update_entity
    RTS
    ; Local label (.skip_enemy) keeps jump distance small
```

## Optimization Checklist

### Before Optimization
- [ ] Profile code to identify hot paths (use emulator cycle counter)
- [ ] Measure baseline performance (frames per second, cycle counts)
- [ ] Identify bottlenecks (NMI handler, main loop, specific functions)

### Zero Page Optimization
- [ ] Move hot variables to zero page (>10 accesses per frame)
- [ ] Use zero page for loop counters in hot loops
- [ ] Use zero page for pointers (16-bit indirect addressing)

### Addressing Mode Optimization
- [ ] Use immediate mode for constants
- [ ] Prefer zero page over absolute addressing
- [ ] Avoid page boundary crossings in hot loops
- [ ] Use indexed addressing efficiently

### Branch Optimization
- [ ] Minimize taken branches in hot paths
- [ ] Structure code to favor not-taken branches
- [ ] Use early exits to reduce nesting
- [ ] Consider lookup tables instead of switch-like branches

### Loop Optimization
- [ ] Unroll small loops (<8 iterations, called frequently)
- [ ] Move loop-invariant code outside loops
- [ ] Use efficient loop termination (CPX vs CMP)
- [ ] Consider struct-of-arrays for batch processing

### Memory Optimization
- [ ] Use struct-of-arrays for entity data
- [ ] Access memory sequentially when possible
- [ ] Minimize memory copies (use pointers)
- [ ] Use ROM lookup tables for computations

### NMI Handler Optimization
- [ ] Use OAM DMA (not byte-by-byte copy)
- [ ] Minimize VRAM writes (batch updates)
- [ ] Keep NMI handler <2000 cycles
- [ ] Move non-critical updates to main loop

### Code Size vs Speed Trade-offs
- [ ] Inline small functions called frequently
- [ ] Use subroutines for large, infrequently called code
- [ ] Consider code duplication for hot paths
- [ ] Balance ROM usage vs CPU cycles

## Performance Measurement

### Cycle Counting
```asm
; Measure function execution time
measure_function:
    ; Function start (read cycle counter in emulator)
    JSR function_to_measure
    ; Function end (read cycle counter)
    ; Difference = execution time
```

### Frame Time Budget
- **Total frame: ~89,400 cycles (NTSC)
- **VBlank: ~2,270 cycles (safe for PPU updates)
- **Visible period: ~81,300 cycles (game logic)
- **NMI handler: Must complete in <2000 cycles

### Profiling Tools
- **Mesen2: Built-in cycle counter and profiler
- **FCEUX: Debugger with cycle counting
- **Manual timing: Use frame counter to measure frame drops

## Common Optimization Mistakes

### Over-Optimization
- **Mistake: Optimizing code that runs once per second
- **Fix: Profile first, optimize hot paths only

### Premature Optimization
- **Mistake: Optimizing before code works
- **Fix: Get it working, then optimize

### Breaking Correctness
- **Mistake: Optimizations that break on real hardware
- **Fix: Test on real hardware, verify timing

### Code Clarity Loss
- **Mistake: Unreadable code for minor speed gains
- **Fix: Balance speed with maintainability

## Optimization Guidelines

1. **Measure First: Use profiler to identify bottlenecks
2. **Optimize Hot Paths: Focus on code that runs every frame
3. **Verify Correctness: Test optimizations on real hardware
4. **Document Changes: Comment why optimization was needed
5. **Balance Trade-offs: Code size vs speed, clarity vs performance

## Related Topics

- [2.1 CPU Timing & Cycles](2.1-cpu-timing-cycles.md) - Understanding cycle counts
- [3.2 Data-Oriented Design](03-core-concepts/3.2-data-oriented-design.md) - Memory layout optimization
- [3.3 Rendering Architecture](03-core-concepts/3.3-rendering-architecture.md) - PPU update optimization
- [4.4 Timing Cheatsheets](04-cheatsheets/4.4-timing-cheatsheets.md) - Quick timing reference

## Cross-References

- Related Fundamentals: 1.2 (6502 CPU), 1.3 (Memory)
- Related Advanced Fundamentals: 2.1 (CPU Timing), 2.2 (NMI & VBlank)
- Related Core Concepts: 3.2 (Data-Oriented Design), 3.3 (Rendering Architecture)
- Related Cheatsheets: 4.1 (CPU), 4.4 (Timing)
